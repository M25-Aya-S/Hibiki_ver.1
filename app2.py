# app.py
import streamlit as st
from openai import OpenAI

# --- ã“ã“ã¯ã‚ãªãŸã®APIã‚­ãƒ¼ ---
client = openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# --- ã²ã³ãã®äººæ ¼ï¼ˆLLM1ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ ---
SYSTEM_PROMPT = """
ã‚ãªãŸã¯ã€Œã²ã³ãã€ã¨ã„ã†å„ªã—ãå¯„ã‚Šæ·»ã†AIã§ã™ã€‚
ä»¥ä¸‹ã®äººæ ¼ã‚’å®ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è©±ã«ä¸å¯§ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚
- å„ªã—ãã€æ€ã„ã‚„ã‚Šã®ã‚ã‚‹èªã‚Šå£
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ°—åˆ†ã‚„å¥½ã¿ã‚’è¦šãˆã¦è‡ªç„¶ã«æ´»ã‹ã™
- éå»ã®è©±é¡Œã‚’ãã£ã¨å¼•ãå‡ºã™
- ä¸å®‰ã‚„æ‚©ã¿ã«å¯„ã‚Šæ·»ã†
- ç„¡ç†ã«åŠ±ã¾ã•ãšãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œä»Šã€ã«åˆã‚ã›ã¦è©±ã™
"""

# --- Streamlit ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– ---
if "messages" not in st.session_state:
    # åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆsystem + ç©ºå±¥æ­´ï¼‰
    st.session_state.messages = [{"role": "system", "content": SYSTEM_PROMPT}]

# --- LLM2ç›¸å½“ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ + éå»è¨˜æ†¶ â†’ LLM1ã¸ã®æŒ‡ç¤ºç”Ÿæˆ ---
def generate_prompt_guidance(user_input, memory=None):
    memory_text = "\n".join(memory) if memory else "è¨˜æ†¶ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
    prompt = f"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã¨è¨˜æ†¶ã‚’è¸ã¾ãˆã¦ã€ä»¥ä¸‹ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
1. èªã‚Šã‹ã‘ã‚¹ã‚¿ã‚¤ãƒ«
2. å‚è€ƒã«ã™ã‚‹è¨˜æ†¶ã®è¦ç´„
3. LLM1ã¸ã®æŒ‡ç¤º

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€:
{user_input}

é–¢é€£è¨˜æ†¶:
{memory_text}
"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": "ã‚ãªãŸã¯ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"}, {"role": "user", "content": prompt}],
        temperature=0.3,
    )
    return response.choices[0].message.content

# --- LLM1ç›¸å½“ï¼šæŒ‡ç¤ºï¼‹äººæ ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ â†’ å¿œç­”ç”Ÿæˆ ---
def generate_response_by_llm1(user_input, instructions):
    final_prompt = f"""
ã‚ãªãŸã¯ã€Œã²ã³ãã€ã¨ã„ã†å„ªã—ã„AIã§ã™ã€‚äººæ ¼ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚
{SYSTEM_PROMPT}

ä»¥ä¸‹ã®æŒ‡ç¤ºã«å¾“ã„ã€1ã€œ2æ–‡ã§è¦ªèº«ã«èªã‚Šã‹ã‘ã¦ãã ã•ã„ã€‚

æŒ‡ç¤º:
{instructions}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€:
{user_input}

ã²ã³ãã®å¿œç­”:
"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": final_prompt}],
        temperature=0.7,
    )
    return response.choices[0].message.content

# --- Streamlit UI ---
st.set_page_config(page_title="ã²ã³ããƒãƒ£ãƒƒãƒˆ", layout="centered")
st.markdown("<h1 style='text-align: center;'>ğŸŒ¸ ã²ã³ãã¨ãŠè©±ã—ã—ã‚ˆã† ğŸŒ¸</h1>", unsafe_allow_html=True)

# éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
for msg in st.session_state.messages[1:]:
    is_user = msg["role"] == "user"
    st.chat_message("ğŸ§‘â€ğŸ’»" if is_user else "ğŸ¤–").markdown(msg["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
user_input = st.chat_input("ã²ã³ãã«è©±ã—ã‹ã‘ã¦ã¿ã¦ã­")
if user_input:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã‚’ãƒãƒ£ãƒƒãƒˆã«è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.chat_message("ğŸ§‘â€ğŸ’»").markdown(user_input)

    # LLM2ã§æŒ‡ç¤ºç”Ÿæˆï¼ˆä»Šã¯è¨˜æ†¶ãªã—ï¼‰
    instructions = generate_prompt_guidance(user_input)

    # LLM1ã§è¿”ç­”ç”Ÿæˆ
    with st.spinner("ã²ã³ããŒè€ƒãˆã¦ã„ã¾ã™..."):
        reply = generate_response_by_llm1(user_input, instructions)

    # è¿”ç­”ã‚’ãƒãƒ£ãƒƒãƒˆã«è¿½åŠ 
    st.session_state.messages.append({"role": "assistant", "content": reply})
    st.chat_message("ğŸ¤–").markdown(reply)
